# Regression analysis of the IODS project 

*This section describes the steps taken to perform regression analysis of data obtained for this IODS project.*

First, let me begin by reading the data for this analysis into R from my local computer. *Please note that the data here was pre-processed through Wrangling from the Helsinki Open data science project, which originally can be  found in this link http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt*   

```{r}
# install.packages("ggplot2")
library(ggplot2)
# Reading the data from my local computer
data <- read.csv("C:\\Users\\fridaya\\Documents\\IODS-project\\data\\learning2014.csv")
learning2014 <- data
```
Now that we have successfully loaded the data to R, we would like to explore the structure and dimension of the data

```{r}
# Here we are checking the structure of the data learning2014
str(learning2014)
```
```{r}
# Here we are checking the dimension of the data learning2014
dim(learning2014)
```
Now we would like to show the graphical overview of the data 

```{r}
# Here, we try to show the graphical entire overview of the data using plot

plot(learning2014)
```
Figure 1

In Figure 1  above, we see the overview of the variables (gender, age, attitude, deep, stra, surf, and points) in the learning2014 data frame. 

*Note* that the variable "gender" scattered plot is not consistent with the other variables. This could be becuase the gender variable did not contain numeric values.

```{r}
# Here, we try to show the graphical overview of the data using pairs excluding the first variable 
pairs(learning2014[-1])
```
Figure 2.

Notice that we repeated the ploting of the variables in learning2014 data by using the pairs function and excluding "gender". 


*interpretations:*

Figure 2 presents the selected variables in diagonal. each row displays a variable on the y-axis and the other variables on the corresponding x- axis. For example, the first row "age" is displayed on the y-axis whereas attitude, deep, stra, and surf are displayed on the x-axis for each of the 5 plots on that row. 


```{r}
# Here we are using three variables to fit our regression model. The variables are attitude, and points, where points is out dependent variable.

library(ggplot2)
qplot(attitude, points, data = learning2014) + geom_smooth(method = "lm")

```

```{r}

# Here we try to fit our a linear model. The dependent variable is points while the explanatory variable is attitude
model <- lm(points ~ attitude, data = learning2014)

# Now let us print the summary of our model
summary(model)
```
*Explanation of the model summary*

In our linear regression model y=α+βx+ϵ, the dependent variable y is "points", and the explanatory variable x is "attitude". 

We computed the summary of the model by calling the lm function lm(formula = points ~ attitude, data = learning2014)

From the summary output of the model, we see the residuals of the model and then the coefficients which estimated values for the parameters of the model. The estimate of the intercept (α) is 11.6372, while the estimate corresponding to the explanatory variable (β) is 3.5255. This imply that the effect of attitude on points is 3.5255 with standard error approx. 0.6 (t = 6.214, p< 0). The summary shows that there is statistically significant relationship between x (attitude) and y (points). 

### Let us fit the model with other explanatory variables (deep, stra, and surf) to see their estimated effect on the dependant variable (points)

```{r}

# Here we try to fit another linear model. The dependent variable is points while the explanatory variable is deep
model <- lm(points ~ deep, data = learning2014)

# Now let us print the summary of our model
summary(model)

```

The summary of this model did not show a significant relationships betwwen deep and points


```{r}

# Here we try to fit another linear model. The dependent variable is points while the explanatory variable is stra
model <- lm(points ~ stra, data = learning2014)

# Now let us print the summary of our model
summary(model)

```

No Significance between stra and points 


```{r}

# Here we try to fit another linear model. The dependent variable is points while the explanatory variable is surf
model <- lm(points ~ surf, data = learning2014)

# Now let us print the summary of our model
summary(model)

```

No significance effect of surf on points

## Multiple regression 
Multiple regression is conducted when there are more than one explanatory variables in a model.
The above situation where each variable was fitted into the simple linear regression to estimate their individual effect on the dependent variable can be made  analysis can be simplified by conducting a multiple regression analysis

```{r}
# We would like to run a multiple regression with this code
model2 <- lm(points ~ attitude + stra + surf, data = learning2014)

# Let us print the summary of our multiple regression 
summary(model2)
```


```{r}
# Here we want to draw the diagnostic plots using the plot() function. 
plot(model2, which = c(1,2,3), caption = list("Residuals vs Fitted", "Normal QQ-plot", "Residuals vs Leverage"))

```

#### Explanation of the diagnostic plots 

1. For the QQ plot, the normality assumption shows reasonable fit to the line implying that the errors of the model are normally distributed.

2.For the Residual VS Fitted plot shows that as the fitted values increases, the scattered plot deviates from the line.

3. For the Residual VS Leverage plot there seems to be no unsual observations noticed in the plot.

